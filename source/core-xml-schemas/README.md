# _core-xml-schemas_ Content Pack

## Contents

The following represents the folder structure and content that will be imported in to _Stroom_ with this content pack.

* _XMLSchemas_ 
    * _analytic-ouput_ 
        * [analytic-output v1.0](#analytic-output) `XMLSchema`
    * _data-splitter_ 
        * [data-splitter v3.0](#data-splitter) `XMLSchema`
    * _json_ 
        * [json](#json) `XMLSchema`
    * _kafka-records_ 
        * [kafka-records v1.0](#kafka-records) `XMLSchema`
    * _records_ 
        * [records v2.0](#records) `XMLSchema`
    * _reference-data_ 
        * [reference-data v2.0.1](#reference-data) `XMLSchema`
    * _statistics_ 
        * [statistics v2.0.1](#statistics) `XMLSchema`
        * [statistics v4.0.0](#statistics) `XMLSchema`

## analytic-output 

This XMLSchema is a data structure for data produced by an analytic of some kind.
The functionality for making use of this schema is currently not included in _Stroom_ and will be added at a later date.

## data-splitter 

This XMLSchema defines the data used to describe a _Data Splitter_ configuration, i.e the regexes and splits to convert a plain text file format into structured XML.

## json 

This schema comes from w3.org and defines the structure used to represent json data as XML.

Data output by the _JSON_ type _Parser_ pipeline element will conform to this XMLSchema.
Data input to the _JsonWriter_ pipeline element must conform to this XMLSchema.

## kafka-records

This structure is intended as an XML representation of a Kafka producer record.
Its intended use is to allow _Stroom_ to publish records onto Kafka topics.
Events/records in _Stroom_ can be translated into this format and then passed to the _KafkaProducer_ for the kafka-records to be published onto a topic.
The structure allows all aspects of a producer record to be defined, such as the partion, key, headers, etc. using XSLT.

## records

This schema defines a structure that is used for holding arbitrary records.
It is typically used as the structure of the data output by a _Data Splitter_ type _Parser_ pipeline element.
It is also used as the normalised form of the application logs (i.e. SLF4J type logs) generated by _Stroom_.

## reference-data

XMLSchema to provide a common structure for describing reference data.
For example a reference data feed may be supplied to _Stroom_ to map IP addresses to fully qualified domain names.
This data feed would either be ingested as data conforming to this XMLSchema or converted into it.

Data input to the _ReferenceDataFilter_ pipeline element must conform to this XMLSchema.

## statistics

Statistic events in _Stroom_ are an abstraction of the rich event records in _Stroom_.
The idea is to condense part of an event down to a count or value with some qualifying attributes, e.g. the number of bytes in a file upload event, or reducing a rich logon event down to a count of 1 with qualifying attributes for the user and device.
These statistic events can then be aggregated in a number of different time buckets for fast querying. 

Statistics data can be recorded in two ways in _Stroom_, either using the internal SQL based statistics store, or by sending the statistic events via _Kafka_ to _Stroom-Stats_.
Each mechanism uses a different version of the Statistics XMLSchema.
The appropriate schema version for each statistics store is as follows:

* SQL Statistics - v2.0.1

* _Stroom-Stats_ - v4.0.0

### SQL Statistics

This statistics store is built in to _Stroom_.  The schema is used to describe a statistics event record.
Statistics are used to record counts (or values) of events happening, e.g. the number of a particular kind of event within a time period, or the CPU% of a _Stroom_ node.

Data fed to the _StatisticsFilter_ pipeline element must conform to this XMLSchema.

### _stroom-stats_ Statistics
_Stroom-Stats_ is external to _Stroom_ and provides a more scalable and feature rich store for statistics data.
The structure of a _Stroom-Stats_ statistic event is broadly similar to a SQL Statistics event, with the addition of some features to support recording references to the source event(s) that contributed to the Statistic event.

Data fed to the `statisticEvents-Count` and `statisticEvents-Value` Kafka topics using _Stroom's_ _KafkaProducerFilter_ pipeline element must conform to this XMLSchema.
