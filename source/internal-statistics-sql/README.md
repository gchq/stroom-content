# _internal-statistics-sql_ Content Pack

When Stroom is running it generates a number of statistics relating to the state of the application, its storage tier and its underlying hardware.
In order to be able to query the internal statistics, this content pack is required.

Internal statistics can currently be recorded by two mechanisms; _SQL Statistics_ and _Stroom-Stats_.
_SQL Statistics_ comes built in with _Stroom_, however _Stroom-Stats_ is an external service.
This pack enables the recording and querying of internal statistics with _SQL_Statistics_.


## Contents

The following represents the folder structure and content that will be imported in to Stroom with either of these content packs.

* _Internal Statistics_ 
    * _SQL_
        * **Benchmark-Cluster Test** `StatisticStore`

            The statistics generated by the _Benchmark Cluster Test_ job. This is a job that runs a set of tasks for benchmarking the system.

            Fields: `Feed`, `Node`, `Type`

        * **CPU** `StatisticStore`

            A number of different statistics relating to the CPU load on a node. The `Type` field is used to qualify the CPU metric being recorded.  Valid values for `Type` are: 

            * `Idle (%)` - The value of the CPU Idle percentage as obtained from /proc/stat.
            * `IO Wait (%)` - The value of the CPU Wait percentage as obtained from /proc/stat.
            * `User (%)` - The value of the CPU User percentage as obtained from /proc/stat.
            * `Irq (%)` - The value of the CPU Irq percentage as obtained from /proc/stat.
            * `Soft Irq (%)` - The value of the CPU Soft Irq percentage as obtained from /proc/stat.
            * `System (%)` - The value of the CPU System percentage as obtained from /proc/stat.
            * `Nice (%)` - The value of the CPU Nice percentage as obtained from /proc/stat.
            * `Total (%)` - The value of the CPU Total percentage as obtained from /proc/stat.

            Any rollup combinations for this statistic should not include the `Type` field as aggregating events of different types is meaningless.

            Fields: `Node`, `Type`

        * **EPS** `StatisticStore`

            A number of different statistics relating to the events processed per second by a node. The `Type` field is used to qualify the metric being recorded.  All values are counts of the number of events processed per second. Valid values for `Type` are: 

            * `Read` - The number of events read per second.
            * `Write` - The number of events written per second.

            Fields: `Node`, `Type`

        * **Heap Histogram Bytes** `StatisticStore`

            When enabled in the _Jobs_ tab, _Stroom_ will run a jmap heap histogram and record each entry as a statistic. The value is the total number of bytes used by all live instances of the class.

            Fields: `Node`, `Class`

        * **Heap Histogram Instances** `StatisticStore`

            When enabled in the _Jobs_ tab, _Stroom_ will run a jmap heap histogram and record each entry as a statistic. The value is the number of live instances of the class.

            Fields: `Node`, `Class`

        * **Memory** `StatisticStore`

            A number of different statistics relating to the JVM memory usage on a node. The `Type` field is used to qualify the memory usage metric being recorded.  All values are in bytes. Valid values for `Type` are: 

            * `Heap Used` - The JVM heap used size in Mb.
            * `Heap Committed` - The JVM heap committed size in Mb.
            * `Heap Max` - The JVM heap maximum size in Mb.
            * `Non Heap Used` - The JVM non heap used size in Mb.
            * `Non Heap Committed` - The JVM non heap committed size in Mb.
            * `Non Heap Max` - The JVM non heap maximum size in Mb.

            Fields: `Node`, `Type`

            Any rollup combinations for this statistic should not include the `Type` field as aggregating events of different types is meaningless.

        * **Meta Data-Stream Size** `StatisticStore`

            Tracks the volume of data (in bytes) received by Feed.

            Fields: `Feed`

        * **Meta Data-Streams Received** `StatisticStore`

            Tracks counts of the number of streams received by Feed.

            Fields: `Feed`

        * **PipelineStreamProcessor** `StatisticStore`

            Fields: `Feed`, `Pipeline`

        * **Stream Task Queue Size** `StatisticStore`

            The number of items on the stream task queue.

            Fields: _None_

        * **Volumes** `StatisticStore`

            A number of different statistics relating to the state of the volumes on Stroom. The `Type` field is used to qualify the metric being recorded.  All values are in bytes. Valid values for `Type` are: 

            * `Limit` - The upper size limit of the volume in bytes. No more data will be written to the volume once this limit is reached.
            * `Used` - The number of bytes in use on the partition that this volume is mounted on.
            * `Free` - The number of bytes of usable space on the partition that the volume is mounted on.
            * `Total` - The total size in bytes of the partition that the volume is mounted on.

            Any rollup combinations for this statistic should not include the `Type` field as aggregating events of different types is meaningless.

            Fields: `Id`, `Node`,  `Path`, `Type`
